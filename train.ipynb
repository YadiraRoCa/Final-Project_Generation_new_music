{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"authorship_tag":"ABX9TyNRbXyBVn+PLrwCMVvVdutC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"3BhLBvhppUl3"},"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as tf\n","import matplotlib.pyplot as plt\n","import PIL\n","from google.colab import drive\n","import scipy.io as sio\n","import numpy as np\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from torchvision.utils import make_grid"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WHrZj5fdoZFs"},"source":["# Dataset Loaders"]},{"cell_type":"code","metadata":{"id":"oAGe8CTBm8lw"},"source":["drive.mount('/content/drive')\n","data_path = '/content/drive/My Drive/DeepLearning_2021/Final_project/proyecto/Data/'\n","results_path = '/content/drive/My Drive/DeepLearning_2021/Final_project/proyecto/Results'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8vDUNMeeogbh"},"source":["**Spectogram data loader definition**"]},{"cell_type":"code","metadata":{"id":"zhTtrVt9ohAJ"},"source":["#@title SPECTOGRAM DATASET CLASS\n","class SPECTOGRAM_128(torch.utils.data.Dataset):\n","    # Initialization method for the dataset\n","    def __init__(self,dataDir, transform = None):\n","        mat_loaded = sio.loadmat(dataDir)\n","        self.data = mat_loaded['X']\n","        self.labels = mat_loaded['label']\n","        self.transform = transform\n","\n","    # What to do to load a single item in the dataset ( read image and label)    \n","    def __getitem__(self, index):\n","        data = self.data[:,:,0,index] \n","        #label = self.labels[0,index]   ####################\n","        #data = Image.fromarray(data,mode='L')\n","        # Apply a trasnformaiton to the image if it is indicated in the initalizer\n","        if self.transform is not None : \n","            data = self.transform(data)\n","        \n","        # return the image and the label\n","        return data,1\n","\n","    # Return the number of images\n","    def __len__(self):\n","        return self.data.shape[3]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8GFk9Fw6o6n_"},"source":["**Visualization functions**"]},{"cell_type":"code","metadata":{"id":"WwWwIXREo7uk"},"source":["#@title Visualize image grid\n","def show_spectograms(image_batch):\n","    image_grid = make_grid(image_batch,nrow=8,padding=1)\n","    image_grid= torch.mean(image_grid,axis=0,keepdim=True)\n","    npimg = image_grid.detach().numpy()\n","    plt.imshow(np.transpose(npimg, (1,2,0)).squeeze(), interpolation='nearest')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPcLMmLDpIsu"},"source":["#@title Load dataset\n","# Test data loader \n","tr = transforms.Compose([\n","        transforms.ToTensor(), \n","        transforms.Normalize(0,1)\n","        ])\n","disco_pop_128 =  SPECTOGRAM_128(data_path+'Disco_Pop_128.mat',tr)\n","train_loader = torch.utils.data.DataLoader(dataset=disco_pop_128,\n","                                           batch_size=64, \n","                                           shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=disco_pop_128,\n","                                           batch_size=32, \n","                                           shuffle=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PuG22Jxipx00"},"source":["# GAN"]},{"cell_type":"code","metadata":{"id":"pfbsH4fQpq_1"},"source":["# Discriminator similar to VAE encoder\n","class Discriminator(nn.Module):\n","  def __init__(self, base_channels=16):\n","    super(Discriminator, self).__init__()\n","    # last fully connected layer acts as a a binary classifier\n","    self.classifier = Encoder(1,base_channels)\n","\n","  # Forward pass obtaining the discriminator probability\n","  def forward(self,x):\n","    out = self.classifier(x)\n","    # use sigmoid to get the real/fake image probability\n","    return torch.sigmoid(out)\n","\n","# Generator is defined as VAE decoder\n","class Generator(nn.Module):\n","  def __init__(self,in_features,base_channels=16):\n","    super(Generator, self).__init__()\n","    self.base_channels = base_channels\n","    self.in_features = in_features\n","    self.decoder = Decoder(in_features,base_channels)\n","\n","  # Generate an image from vector z\n","  def forward(self,z):\n","    return torch.sigmoid(self.decoder(z))\n","\n","  # Sample a set of images from random vectors z\n","  def sample(self,n_samples=256,device='cpu'):\n","    samples_unit_normal = torch.randn((n_samples,self.in_features)).to(device)\n","    return self.decoder(samples_unit_normal)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIncfIR5p03E"},"source":["def train_GAN(gen, disc,  train_loader, optimizer_gen, optim_disc,\n","              num_epochs=10, model_name='gan_disco_pop.ckpt', device='cpu'):\n","    gen = gen.to(device)\n","    gen.train() # Set the generator in train mode\n","    disc = disc.to(device)\n","    disc.train() # Set the discriminator in train mode\n","\n","    total_step = len(train_loader)\n","    losses_list = []\n","\n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        # Iterate the dataset\n","        disc_loss_avg = 0\n","        gen_loss_avg = 0\n","        nBatches = 0\n","        update_generator = True\n","\n","        for i, (real_images) in enumerate(train_loader): ################ real_images,labels\n","            # Get batch of samples and labels\n","            real_images = real_images.float().to(device) / 255\n","            n_images = real_images.shape[0]\n","\n","            # Forward pass\n","            # Generate random images with the generator\n","            fake_images = gen.sample(n_images,device=device)\n","            \n","            # Use the discriminator to obtain the probabilties for real and generate imee\n","            prob_real = disc(real_images)\n","            prob_fake = disc(fake_images)\n","            \n","            # Generator loss\n","            gen_loss = -torch.log(prob_fake).mean()\n","            # Discriminator loss\n","            disc_loss = -0.5*(torch.log(prob_real) + torch.log(1-prob_fake)).mean()\n","\n","            \n","            # We are going to update the discriminator and generator parameters alternatively at each iteration\n","\n","            if (update_generator):\n","              # Optimize generator\n","              # Backward and optimize\n","              optimizer_gen.zero_grad()\n","              gen_loss.backward() # Necessary to not erase intermediate variables needed for computing disc_loss gradient\n","              optimizer_gen.step()\n","              update_generator = False\n","            else:           \n","              # Optimize discriminator\n","              # Backward and optimize\n","              optimizer_disc.zero_grad()\n","              disc_loss.backward()\n","              optimizer_disc.step()\n","              update_generator = True\n","                \n","\n","            disc_loss_avg += disc_loss.cpu().item()\n","            gen_loss_avg += gen_loss.cpu().item()\n","\n","            nBatches+=1\n","            if (i+1) % 200 == 0:\n","                print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches))\n","        print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches))\n","        # Save model\n","        losses_list.append(disc_loss_avg / nBatches)\n","        torch.save(gan_gen.state_dict(), results_path+ '/' + model_name)\n","          \n","    return losses_list "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qPNQ_FkQp_vs"},"source":["## Trainning a GAN"]},{"cell_type":"code","metadata":{"id":"8aCwhtcyp7I0"},"source":["# Define Geneartor and Discriminator networks\n","gan_gen = Generator(32)\n","gan_disc = Discriminator()\n","\n","#Initialize indepdent optimizer for both networks\n","learning_rate = .0005\n","optimizer_gen = torch.optim.Adam(gan_gen.parameters(),lr = learning_rate, weight_decay=1e-5)\n","optimizer_disc = torch.optim.Adam(gan_disc.parameters(),lr = learning_rate, weight_decay=1e-5)\n","\n","# Train the GAN\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","loss_list = train_GAN(gan_gen,gan_disc, train_loader, optimizer_gen, optimizer_disc,\n","                      num_epochs=20, model_name='gan_disco_pop.ckpt', device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bpNTWYZnqFdu"},"source":["## Visualize synthetic images"]},{"cell_type":"code","metadata":{"id":"uweCR-vxqKik"},"source":["# Load generator\n","gan_gen = Generator(32)\n","gan_gen.load_state_dict(torch.load(results_path+'/gan_disco_pop.ckpt',map_location=torch.device('cpu')))\n","gan_gen.eval() # Put in eval model\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","gan_gen = gan_gen.to(device)\n","\n","# Generate random images from sampled vectors z and visualize them \n","x_gen = gan_gen.sample(64,device=device)\n","show_spectograms(x_gen.cpu())\n","# image_grid = make_grid(x_gen.cpu(),nrow=8,padding=1)\n","# plt.figure(figsize=(8,8))\n","# plt.imshow(image_grid.permute(1,2,0).detach().numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7-LJtbAqQlD"},"source":["# Save the images"]},{"cell_type":"code","metadata":{"id":"Y3xgM68yqdpS"},"source":["from PIL import Image\n","\n","for i in range(len(x_gen)):\n","  data = x_gen[i,:,:,:].cpu().detach().numpy().squeeze()\n","  #Rescale to 0-255 and convert to uint8\n","  rescaled = (255.0 / data.max() * (data - data.min())).astype(np.uint8)\n","  im = Image.fromarray(rescaled,mode='L')\n","  im.save(results_path + f'/test_{i}.png')"],"execution_count":null,"outputs":[]}]}